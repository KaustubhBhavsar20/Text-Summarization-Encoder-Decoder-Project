{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGMRjg9CEytR",
    "outputId": "71c1fd02-fe6e-4128-a092-8b78e806025b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from rouge import Rouge\n",
    "summary = pd.read_csv('/content/drive/MyDrive/News/news_summary.csv', encoding='iso-8859-1')\n",
    "raw = pd.read_csv('/content/drive/MyDrive/News/news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5Xv8zc9_FTIF"
   },
   "outputs": [],
   "source": [
    "pre1 =  raw.iloc[:,0:2].copy()\n",
    "# pre1['head + text'] = pre1['headlines'].str.cat(pre1['text'], sep =\" \")\n",
    "\n",
    "pre2 = summary.iloc[:,0:6].copy()\n",
    "pre2['text'] = pre2['author'].str.cat(pre2['date'].str.cat(pre2['read_more'].str.cat(pre2['text'].str.cat(pre2['ctext'], sep = \" \"), sep =\" \"),sep= \" \"), sep = \" \")\n",
    "\n",
    "pre1=pre1.head(1000)\n",
    "pre2=pre2.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "76DTWS2rGGaj"
   },
   "outputs": [],
   "source": [
    "pre = pd.DataFrame()\n",
    "pre['text'] = pd.concat([pre1['text'], pre2['text']], ignore_index=True)\n",
    "pre['summary'] = pd.concat([pre1['headlines'],pre2['headlines']],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "3B4uLVIdGI4f",
    "outputId": "900dfcda-b293-4df3-d92c-121da2d36b2b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"pre\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1991,\n        \"samples\": [\n          \"Two Chinese companies have announced an extra eight days of annual 'dating leave' for unmarried single women employees aged over 30 years in non-frontline roles. The leaves will be given every year over the Chinese New Year to \\\"go home and date\\\", the company said. The leaves come into effect over the Chinese New Year on February 5.\",\n          \"Daisy Mowke 23 Jul 2017,Sunday http://indiatoday.intoday.in/story/shahid-kapoor-rangoon-failure-padmavati/1/1009013.html?utm_source=inshorts&utm_medium=referral&utm_campaign=fullarticle  Shahid Kapoor, while speaking about the failure of Rangoon, said he cannot take ownership of the film. \\\"Rangoon as a film had many energies and many people... I'm happy my part was appreciated but I'm sad for the film not doing well,\\\" he added. Shahid further said it's disheartening when a film doesn't do good business and doesn't get appreciation. When Shahid Kapoor and Vishal Bharadwaj announced their third collaboration after Kaminey and Haider, the expectations were sky-high. However, Rangoon failed to set the cash registers ringing and fizzled out at the box office after earning only around Rs 20 crore.In an interview with Filmfare, Shahid talked about the debacle of his last release. \\\"When a film doesn't do the kind of business or get the appreciation it should get, it's heartbreaking. I was fortunate that people liked me in Rangoon... Regardless of anything, people have liked my work in his films. I was happy I got recognised. But I am sure when we work together again we will do something great,\\\" the actor said.Shahid added that the failure of the film was not on him. \\\"Rangoon as a film had many energies and many people. I can't take ownership of the film. I am happy my part was appreciated but I am sad for the film not doing well,\\\" he said.Shahid will be seen next in Sanjay Leela Bhansali's Padmavati, which also features Deepika Padukone and Ranveer Singh. The film is scheduled to release in November this year.\",\n          \"The Indian duo of Virat Kohli and Rohit Sharma reached the joint third place in the list of most century stands in ODI cricket after going past the landmark in the 3rd India-New Zealand ODI. The duo, who registered their 16th century stand on Monday, are 10 century stands behind Sachin Tendulkar and Sourav Ganguly's tally. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"Authorities plan night patrols to curb Noida sand mining\",\n          \"Pak to resume talks with India only after polls: Minister\",\n          \"Delhi man beaten to death for not paying back ?1,500\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "pre"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-ec08a6ca-b268-4eed-b233-7e7af349ee8b\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ec08a6ca-b268-4eed-b233-7e7af349ee8b')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ec08a6ca-b268-4eed-b233-7e7af349ee8b button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ec08a6ca-b268-4eed-b233-7e7af349ee8b');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-fde0cd52-96bb-4366-abc4-99d5ca70ec1f\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fde0cd52-96bb-4366-abc4-99d5ca70ec1f')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-fde0cd52-96bb-4366-abc4-99d5ca70ec1f button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...   \n",
       "1  Kunal Shah's credit card bill payment platform...   \n",
       "\n",
       "                                             summary  \n",
       "0  upGrad learner switches to career in ML & Al w...  \n",
       "1  Delhi techie wins free food from Swiggy for on...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "id": "5wRkfZrEGLb5",
    "outputId": "7294e36c-61d3-498b-c534-c4e1037b053f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-self-attention\n",
      "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-self-attention) (1.26.4)\n",
      "Building wheels for collected packages: keras-self-attention\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18895 sha256=96ba1c078a546864717ef788ea0489bdc3eb2c6f2c9d5a92192d3a62f72ca5f6\n",
      "  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n",
      "Successfully built keras-self-attention\n",
      "Installing collected packages: keras-self-attention\n",
      "Successfully installed keras-self-attention-0.51.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistani singer Rahat Fateh Ali Khan has deni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>India recorded their lowest ODI total in New Z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Weeks after ex-CBI Director Alok Verma told th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Andhra Pradesh CM N Chandrababu Naidu has said...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Congress candidate Shafia Zubair won the Ramga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> object</label>"
      ],
      "text/plain": [
       "0    Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
       "1    Kunal Shah's credit card bill payment platform...\n",
       "2    New Zealand defeated India by 8 wickets in the...\n",
       "3    With Aegon Life iTerm Insurance plan, customer...\n",
       "4    Speaking about the sexual harassment allegatio...\n",
       "5    Pakistani singer Rahat Fateh Ali Khan has deni...\n",
       "6    India recorded their lowest ODI total in New Z...\n",
       "7    Weeks after ex-CBI Director Alok Verma told th...\n",
       "8    Andhra Pradesh CM N Chandrababu Naidu has said...\n",
       "9    Congress candidate Shafia Zubair won the Ramga...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LSTM with Attention\n",
    "!pip install keras-self-attention\n",
    "\n",
    "pre['text'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "eZV5BHvQGQJo"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#Removes non-alphabetic characters:\n",
    "def text_strip(column):\n",
    "    for row in column:\n",
    "\n",
    "        #ORDER OF REGEX IS VERY VERY IMPORTANT!!!!!!\n",
    "\n",
    "        row=re.sub(\"(\\\\t)\", ' ', str(row)).lower() #remove escape charecters\n",
    "        row=re.sub(\"(\\\\r)\", ' ', str(row)).lower()\n",
    "        row=re.sub(\"(\\\\n)\", ' ', str(row)).lower()\n",
    "\n",
    "        row=re.sub(\"(__+)\", ' ', str(row)).lower()   #remove _ if it occors more than one time consecutively\n",
    "        row=re.sub(\"(--+)\", ' ', str(row)).lower()   #remove - if it occors more than one time consecutively\n",
    "        row=re.sub(\"(~~+)\", ' ', str(row)).lower()   #remove ~ if it occors more than one time consecutively\n",
    "        row=re.sub(\"(\\+\\++)\", ' ', str(row)).lower()   #remove + if it occors more than one time consecutively\n",
    "        row=re.sub(\"(\\.\\.+)\", ' ', str(row)).lower()   #remove . if it occors more than one time consecutively\n",
    "\n",
    "        row=re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", ' ', str(row)).lower() #remove <>()|&©ø\"',;?~*!\n",
    "\n",
    "        row=re.sub(\"(mailto:)\", ' ', str(row)).lower() #remove mailto:\n",
    "        row=re.sub(r\"(\\\\x9\\d)\", ' ', str(row)).lower() #remove \\x9* in text\n",
    "        row=re.sub(\"([iI][nN][cC]\\d+)\", 'INC_NUM', str(row)).lower() #replace INC nums to INC_NUM\n",
    "        row=re.sub(\"([cC][mM]\\d+)|([cC][hH][gG]\\d+)\", 'CM_NUM', str(row)).lower() #replace CM# and CHG# to CM_NUM\n",
    "\n",
    "\n",
    "        row=re.sub(\"(\\.\\s+)\", ' ', str(row)).lower() #remove full stop at end of words(not between)\n",
    "        row=re.sub(\"(\\-\\s+)\", ' ', str(row)).lower() #remove - at end of words(not between)\n",
    "        row=re.sub(\"(\\:\\s+)\", ' ', str(row)).lower() #remove : at end of words(not between)\n",
    "\n",
    "        row=re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower() #remove any single charecters hanging between 2 spaces\n",
    "\n",
    "        #Replace any url as such https://abc.xyz.net/browse/sdf-5327 ====> abc.xyz.net\n",
    "        try:\n",
    "            url = re.search(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)', str(row))\n",
    "            repl_url = url.group(3)\n",
    "            row = re.sub(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)',repl_url, str(row))\n",
    "        except:\n",
    "            pass #there might be emails with no url in them\n",
    "\n",
    "\n",
    "\n",
    "        row = re.sub(\"(\\s+)\",' ',str(row)).lower() #remove multiple spaces\n",
    "\n",
    "        #Should always be last\n",
    "        row=re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower() #remove any single charecters hanging between 2 spaces\n",
    "\n",
    "\n",
    "\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SzFD1Kw1GWK7"
   },
   "outputs": [],
   "source": [
    "brief_cleaning1 = text_strip(pre['text'])\n",
    "brief_cleaning2 = text_strip(pre['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OLzpGHBQGYL3",
    "outputId": "c275c8f1-6086-4f43-a730-f5b2b30a3b84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.13.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "Time to clean up everything: 0.92 mins\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['ner', 'parser'])\n",
    "#Taking advantage of spaCy .pipe() method to speed-up the cleaning process:\n",
    "#If data loss seems to be happening(i.e len(text) = 50 instead of 75 etc etc) in this cell , decrease the batch_size parametre\n",
    "\n",
    "t = time()\n",
    "\n",
    "#Batch the data points into 5000 and run on all cores for faster preprocessing\n",
    "# The n_threads argument has been removed. spaCy now automatically manages threading.\n",
    "text = [str(doc) for doc in nlp.pipe(brief_cleaning1, batch_size=5000)]\n",
    "\n",
    "#Takes 7-8 mins\n",
    "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZ0yndUTGbjR",
    "outputId": "f4a92ebd-8e55-44f7-f383-1381a8e3c8b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.13.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "Time to clean up everything: 0.07 mins\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['ner', 'parser'])\n",
    "\n",
    "t = time()\n",
    "\n",
    "summary = ['_START_ '+ str(doc) + ' _END_' for doc in nlp.pipe(brief_cleaning2, batch_size=5000)]\n",
    "\n",
    "#Takes 7-8 mins\n",
    "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "6BPDFlb2HPXk",
    "outputId": "ad5ead1b-0e9e-4ce9-9a65-cff02483beb1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'saurav kant an alumnus of upgrad and iiit-b pg program in machine learning and artificial intelligence was sr systems engineer at infosys with almost years of work experience the program and upgrad 360-degree career support helped him transition to data scientist at tech mahindra with 90% salary hike upgrad online power learning has powered lakh+ careers.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "vymsaKG_Hh-U",
    "outputId": "cfb17c49-5735-4ed2-d3d7-806184eb3d56"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'_START_ upgrad learner switches to career in ml al with 90% salary hike _END_'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "OvsMQe_IHnzF"
   },
   "outputs": [],
   "source": [
    "pre['cleaned_text'] = pd.Series(text)\n",
    "pre['cleaned_summary'] = pd.Series(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "2A5TiKAJHoht"
   },
   "outputs": [],
   "source": [
    "text_count = []\n",
    "summary_count = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8_IJPMNwHrBq"
   },
   "outputs": [],
   "source": [
    "for sent in pre['cleaned_text']:\n",
    "    text_count.append(len(sent.split()))\n",
    "for sent in pre['cleaned_summary']:\n",
    "    summary_count.append(len(sent.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ZReTg6TCHvB4"
   },
   "outputs": [],
   "source": [
    "graph_df= pd.DataFrame()\n",
    "graph_df['text']=text_count\n",
    "graph_df['summary']=summary_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "RFHXQ2mFHwn3",
    "outputId": "6a3a9dd1-df44-4ec1-91b0-c2413c92a688"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "graph_df.hist(bins = 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nN2plDqbHyg1",
    "outputId": "e72c087d-b5c5-4157-d636-78594fedba3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994\n"
     ]
    }
   ],
   "source": [
    "#Check how much % of summary have 0-15 words\n",
    "cnt=0\n",
    "for i in pre['cleaned_summary']:\n",
    "    if(len(i.split())<=15):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(pre['cleaned_summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GBRZ3AyqH1Vv",
    "outputId": "bc343b62-0889-469f-d515-2a34fe7fbb83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5055\n"
     ]
    }
   ],
   "source": [
    "#Check how much % of text have 0-70 words\n",
    "cnt=0\n",
    "for i in pre['cleaned_text']:\n",
    "    if(len(i.split())<=100):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(pre['cleaned_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "oxxd0c1zH3Tr"
   },
   "outputs": [],
   "source": [
    "#Model to summarize the text between 0-15 words for Summary and 0-100 words for Text\n",
    "max_text_len=100\n",
    "max_summary_len=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "xGoq9NLiH5n3"
   },
   "outputs": [],
   "source": [
    "#Select the Summaries and Text between max len defined above\n",
    "\n",
    "cleaned_text =np.array(pre['cleaned_text'])\n",
    "cleaned_summary=np.array(pre['cleaned_summary'])\n",
    "\n",
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "\n",
    "post_pre=pd.DataFrame({'text':short_text,'summary':short_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "QFSyhvMPH8CI",
    "outputId": "2f9f9a21-97d5-421c-8a9b-8b8a868acce1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"post_pre\",\n  \"rows\": 999,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 991,\n        \"samples\": [\n          \"actor nawazuddin siddiqui in recent interview said bollywood stars play only positive roles throughout their lives on being asked why he plays so many negative roles on screen nawazuddin said negative characters used to exist in earlier films when the villains only had negative qualities why don you ask stars why don they play negative roles he added.\",\n          \"former indian cricketer sunil gavaskar praised hardik pandya performance in the 3rd india-new zealand odi saying terrific performance absolutely terrific performance it never easy gavaskar further said he is young man he has had things that have happened and he just wants to forget it the best way to forget it is being out on the field \",\n          \"world number one novak djokovic defeated world number two rafael nadal in straight sets in the men singles final on sunday to win australian open for record seventh time this is the third time that the 31-year-old serbian has won three consecutive grand slams titles djokovic has now won 15 grand slam titles third-most by male tennis player.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 999,\n        \"samples\": [\n          \"_START_ dale steyn mom wishes her son for match day after it got over _END_\",\n          \"_START_ sc refuses to stay 10% general category quota says will examine it _END_\",\n          \"_START_ rana kapoor madhu kapur to nominate director each to yes bank _END_\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "post_pre"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-be6bf31b-4b4e-43dc-8d29-dfa0ce015d1d\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saurav kant an alumnus of upgrad and iiit-b pg...</td>\n",
       "      <td>_START_ upgrad learner switches to career in m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "      <td>_START_ delhi techie wins free food from swigg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be6bf31b-4b4e-43dc-8d29-dfa0ce015d1d')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-be6bf31b-4b4e-43dc-8d29-dfa0ce015d1d button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-be6bf31b-4b4e-43dc-8d29-dfa0ce015d1d');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-d300c524-1a7b-4b3d-a905-7a70dfb2229f\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d300c524-1a7b-4b3d-a905-7a70dfb2229f')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-d300c524-1a7b-4b3d-a905-7a70dfb2229f button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  saurav kant an alumnus of upgrad and iiit-b pg...   \n",
       "1  kunal shah credit card bill payment platform c...   \n",
       "\n",
       "                                             summary  \n",
       "0  _START_ upgrad learner switches to career in m...  \n",
       "1  _START_ delhi techie wins free food from swigg...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_pre.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "NWgbSl0WH-Sc"
   },
   "outputs": [],
   "source": [
    "#Add sostok and eostok at\n",
    "post_pre['summary'] = post_pre['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "XhUjgzIkIAiE",
    "outputId": "6e07f14d-17d8-455b-c389-9d6b691c9538"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"post_pre\",\n  \"rows\": 999,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 991,\n        \"samples\": [\n          \"actor nawazuddin siddiqui in recent interview said bollywood stars play only positive roles throughout their lives on being asked why he plays so many negative roles on screen nawazuddin said negative characters used to exist in earlier films when the villains only had negative qualities why don you ask stars why don they play negative roles he added.\",\n          \"former indian cricketer sunil gavaskar praised hardik pandya performance in the 3rd india-new zealand odi saying terrific performance absolutely terrific performance it never easy gavaskar further said he is young man he has had things that have happened and he just wants to forget it the best way to forget it is being out on the field \",\n          \"world number one novak djokovic defeated world number two rafael nadal in straight sets in the men singles final on sunday to win australian open for record seventh time this is the third time that the 31-year-old serbian has won three consecutive grand slams titles djokovic has now won 15 grand slam titles third-most by male tennis player.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 999,\n        \"samples\": [\n          \"sostok _START_ dale steyn mom wishes her son for match day after it got over _END_ eostok\",\n          \"sostok _START_ sc refuses to stay 10% general category quota says will examine it _END_ eostok\",\n          \"sostok _START_ rana kapoor madhu kapur to nominate director each to yes bank _END_ eostok\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "post_pre"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-fa9dce8b-5097-48bd-813d-8898f72e90de\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saurav kant an alumnus of upgrad and iiit-b pg...</td>\n",
       "      <td>sostok _START_ upgrad learner switches to care...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "      <td>sostok _START_ delhi techie wins free food fro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa9dce8b-5097-48bd-813d-8898f72e90de')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-fa9dce8b-5097-48bd-813d-8898f72e90de button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-fa9dce8b-5097-48bd-813d-8898f72e90de');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-4655fc45-af3c-4900-bc0a-1f736847784f\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4655fc45-af3c-4900-bc0a-1f736847784f')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-4655fc45-af3c-4900-bc0a-1f736847784f button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  saurav kant an alumnus of upgrad and iiit-b pg...   \n",
       "1  kunal shah credit card bill payment platform c...   \n",
       "\n",
       "                                             summary  \n",
       "0  sostok _START_ upgrad learner switches to care...  \n",
       "1  sostok _START_ delhi techie wins free food fro...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_pre.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "FaVQt_5rIDD-"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(post_pre['text']),np.array(post_pre['summary']),test_size=0.1,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "wY8t1f-VIExU"
   },
   "outputs": [],
   "source": [
    "#Lets tokenize the text to get the vocab count , you can use Spacy here also\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer()\n",
    "x_tokenizer.fit_on_texts(list(x_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "twiLPRowIGnY",
    "outputId": "9c81b29d-366a-4a46-b7a1-5de1a47d2d0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 75.60757083659985\n",
      "Total Coverage of rare words: 18.843851024351054\n"
     ]
    }
   ],
   "source": [
    "thresh=4\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "\n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CTAVuuraIMpS",
    "outputId": "9e5089d6-22d5-4e0d-8c42-d814ac946c07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary in X = 2179\n"
     ]
    }
   ],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt)\n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences (i.e one-hot encodeing all the words)\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr)\n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1\n",
    "\n",
    "print(\"Size of vocabulary in X = {}\".format(x_voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "8J-mlQTJIPxF"
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer()\n",
    "y_tokenizer.fit_on_texts(list(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4zBqcaTgIRz4",
    "outputId": "4765485b-dc28-4ed0-b4ee-4a3ccb1fd177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 92.96939619520265\n",
      "Total Coverage of rare words: 40.9997634629031\n"
     ]
    }
   ],
   "source": [
    "thresh=6\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "\n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cYN0jrvMIT24",
    "outputId": "da3cbeb2-887e-4ce7-af5e-24d893f40e53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary in Y = 256\n"
     ]
    }
   ],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt)\n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert text sequences into integer sequences (i.e one hot encode the text in Y)\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr)\n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1\n",
    "print(\"Size of vocabulary in Y = {}\".format(y_voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "StBWajnZIWMt"
   },
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_tr)):\n",
    "    cnt=0\n",
    "    for j in y_tr[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr=np.delete(y_tr,ind, axis=0)\n",
    "x_tr=np.delete(x_tr,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "miIzPeivIYXj"
   },
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_val)):\n",
    "    cnt=0\n",
    "    for j in y_val[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_val=np.delete(y_val,ind, axis=0)\n",
    "x_val=np.delete(x_val,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "id": "EGO3_Y3zIaKl",
    "outputId": "7950c04a-1c89-4577-ef1d-543ffecb0ddd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary from the w2v model = 2179\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">435,800</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">601,200</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │                        │\n",
       "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]                  │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │                        │\n",
       "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]                  │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">51,200</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │                        │\n",
       "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]                  │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">601,200</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],          │\n",
       "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]                  │                │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]           │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ time_distributed          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">77,056</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)         │                        │                │                        │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │        \u001b[38;5;34m435,800\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)               │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m300\u001b[0m),     │        \u001b[38;5;34m601,200\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │                        │\n",
       "│                           │ \u001b[38;5;34m300\u001b[0m)]                  │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m300\u001b[0m),     │        \u001b[38;5;34m721,200\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │                        │\n",
       "│                           │ \u001b[38;5;34m300\u001b[0m)]                  │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)      │         \u001b[38;5;34m51,200\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m300\u001b[0m),     │        \u001b[38;5;34m721,200\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │                        │\n",
       "│                           │ \u001b[38;5;34m300\u001b[0m)]                  │                │                        │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m),    │        \u001b[38;5;34m601,200\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],          │\n",
       "│                           │ \u001b[38;5;34m300\u001b[0m)]                  │                │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]           │\n",
       "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
       "│ time_distributed          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m77,056\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)         │                        │                │                        │\n",
       "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,208,856</span> (12.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,208,856\u001b[0m (12.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,208,856</span> (12.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,208,856\u001b[0m (12.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import gensim\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Size of vocabulary from the w2v model = {}\".format(x_voc))\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=200\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3 \n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "RwcLo6-ZIfE1"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "9ClJOz46Iodm"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xoO1TIKxIsf6",
    "outputId": "a6689c9d-2046-4adf-81e1-766f00573850"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5s/step - loss: 2.3669 - val_loss: 2.1229\n",
      "Epoch 2/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 4s/step - loss: 2.1901 - val_loss: 1.9402\n",
      "Epoch 3/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4s/step - loss: 2.0033 - val_loss: 2.1850\n",
      "Epoch 4/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4s/step - loss: 2.0960 - val_loss: 1.8077\n",
      "Epoch 5/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 5s/step - loss: 1.8517 - val_loss: 1.7875\n",
      "Epoch 6/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4s/step - loss: 1.8528 - val_loss: 1.7641\n",
      "Epoch 7/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4s/step - loss: 1.8293 - val_loss: 1.7740\n",
      "Epoch 8/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4s/step - loss: 1.7955 - val_loss: 1.6640\n",
      "Epoch 9/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4s/step - loss: 1.7384 - val_loss: 1.6550\n",
      "Epoch 10/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4s/step - loss: 1.7228 - val_loss: 1.6347\n",
      "Epoch 11/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4s/step - loss: 1.7303 - val_loss: 1.6412\n",
      "Epoch 12/25\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 4s/step - loss: 1.7280 - val_loss: 1.6550\n",
      "Epoch 12: early stopping\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=25,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Ndr-kt1I6tt",
    "outputId": "9af9b2d1-80c0-43dd-a531-1fb51c3809b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Save the model to the current directory or a specific path\n",
    "model_path = '/content/drive/MyDrive/News/news_model.h5'  # Specify the path where you want to save the model\n",
    "model.save(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xApbxOjLnDh",
    "outputId": "dad5a025-c155-4556-ebc5-570aba40a334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 802ms/step\n",
      "Classification report for output column 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           1.00       100\n",
      "   macro avg       1.00      1.00      1.00       100\n",
      "weighted avg       1.00      1.00      1.00       100\n",
      "\n",
      "------------------------------\n",
      "Classification report for output column 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         1\n",
      "           5       0.08      1.00      0.15         8\n",
      "           6       0.00      0.00      0.00         7\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         3\n",
      "          10       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       0.00      0.00      0.00         3\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         2\n",
      "          18       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         3\n",
      "          26       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         1\n",
      "          31       0.00      0.00      0.00         1\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00         1\n",
      "          35       0.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00         1\n",
      "          52       0.00      0.00      0.00         2\n",
      "          55       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         1\n",
      "          65       0.00      0.00      0.00         2\n",
      "          66       0.00      0.00      0.00         1\n",
      "          70       0.00      0.00      0.00         2\n",
      "          79       0.00      0.00      0.00         2\n",
      "          81       0.00      0.00      0.00         1\n",
      "          83       0.00      0.00      0.00         1\n",
      "          86       0.00      0.00      0.00         4\n",
      "          90       0.00      0.00      0.00         2\n",
      "          92       0.00      0.00      0.00         1\n",
      "          95       0.00      0.00      0.00         1\n",
      "         103       0.00      0.00      0.00         1\n",
      "         105       0.00      0.00      0.00         1\n",
      "         106       0.00      0.00      0.00         1\n",
      "         113       0.00      0.00      0.00         2\n",
      "         114       0.00      0.00      0.00         3\n",
      "         117       0.00      0.00      0.00         1\n",
      "         127       0.00      0.00      0.00         1\n",
      "         139       0.00      0.00      0.00         1\n",
      "         144       0.00      0.00      0.00         1\n",
      "         157       0.00      0.00      0.00         1\n",
      "         173       0.00      0.00      0.00         1\n",
      "         176       0.00      0.00      0.00         1\n",
      "         177       0.00      0.00      0.00         1\n",
      "         180       0.00      0.00      0.00         1\n",
      "         185       0.00      0.00      0.00         1\n",
      "         193       0.00      0.00      0.00         1\n",
      "         203       0.00      0.00      0.00         1\n",
      "         209       0.00      0.00      0.00         1\n",
      "         211       0.00      0.00      0.00         1\n",
      "         212       0.00      0.00      0.00         2\n",
      "         213       0.00      0.00      0.00         1\n",
      "         215       0.00      0.00      0.00         1\n",
      "         233       0.00      0.00      0.00         1\n",
      "         241       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.08       100\n",
      "   macro avg       0.00      0.02      0.00       100\n",
      "weighted avg       0.01      0.08      0.01       100\n",
      "\n",
      "------------------------------\n",
      "Classification report for output column 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         9\n",
      "           4       1.00      1.00      1.00         1\n",
      "           5       0.09      1.00      0.17         9\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00         6\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.00      0.00      0.00         3\n",
      "          15       0.00      0.00      0.00         4\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         1\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         1\n",
      "          29       0.00      0.00      0.00         1\n",
      "          30       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00         1\n",
      "          35       0.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         1\n",
      "          40       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         1\n",
      "          54       0.00      0.00      0.00         2\n",
      "          55       0.00      0.00      0.00         1\n",
      "          56       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          61       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         1\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.00      0.00      0.00         1\n",
      "          86       0.00      0.00      0.00         1\n",
      "          87       0.00      0.00      0.00         1\n",
      "          95       0.00      0.00      0.00         1\n",
      "          98       0.00      0.00      0.00         1\n",
      "         100       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         2\n",
      "         113       0.00      0.00      0.00         1\n",
      "         123       0.00      0.00      0.00         1\n",
      "         125       0.00      0.00      0.00         1\n",
      "         126       0.00      0.00      0.00         1\n",
      "         131       0.00      0.00      0.00         1\n",
      "         135       0.00      0.00      0.00         2\n",
      "         137       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         1\n",
      "         144       0.00      0.00      0.00         1\n",
      "         158       0.00      0.00      0.00         2\n",
      "         159       0.00      0.00      0.00         1\n",
      "         161       0.00      0.00      0.00         1\n",
      "         162       0.00      0.00      0.00         1\n",
      "         179       0.00      0.00      0.00         1\n",
      "         188       0.00      0.00      0.00         2\n",
      "         195       0.00      0.00      0.00         1\n",
      "         199       0.00      0.00      0.00         1\n",
      "         201       0.00      0.00      0.00         1\n",
      "         213       0.00      0.00      0.00         1\n",
      "         230       0.00      0.00      0.00         1\n",
      "         247       0.00      0.00      0.00         1\n",
      "         249       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.10       100\n",
      "   macro avg       0.02      0.03      0.02       100\n",
      "weighted avg       0.02      0.10      0.03       100\n",
      "\n",
      "------------------------------\n",
      "Classification report for output column 4:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       0.11      1.00      0.20        10\n",
      "           4       1.00      1.00      1.00         9\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.00      0.00      0.00         5\n",
      "           7       0.00      0.00      0.00         4\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.00      0.00      0.00         3\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       0.00      0.00      0.00         3\n",
      "          12       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         3\n",
      "          21       0.00      0.00      0.00         1\n",
      "          24       0.00      0.00      0.00         2\n",
      "          30       0.00      0.00      0.00         2\n",
      "          31       0.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         1\n",
      "          47       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         1\n",
      "          52       0.00      0.00      0.00         1\n",
      "          61       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         1\n",
      "          65       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         1\n",
      "          73       0.00      0.00      0.00         1\n",
      "          75       0.00      0.00      0.00         2\n",
      "          76       0.00      0.00      0.00         2\n",
      "          78       0.00      0.00      0.00         1\n",
      "          83       0.00      0.00      0.00         2\n",
      "          85       0.00      0.00      0.00         1\n",
      "          86       0.00      0.00      0.00         1\n",
      "          89       0.00      0.00      0.00         1\n",
      "          98       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         1\n",
      "         102       0.00      0.00      0.00         1\n",
      "         109       0.00      0.00      0.00         1\n",
      "         122       0.00      0.00      0.00         1\n",
      "         131       0.00      0.00      0.00         1\n",
      "         132       0.00      0.00      0.00         1\n",
      "         142       0.00      0.00      0.00         1\n",
      "         144       0.00      0.00      0.00         1\n",
      "         146       0.00      0.00      0.00         1\n",
      "         152       0.00      0.00      0.00         1\n",
      "         174       0.00      0.00      0.00         1\n",
      "         182       0.00      0.00      0.00         1\n",
      "         193       0.00      0.00      0.00         1\n",
      "         194       0.00      0.00      0.00         1\n",
      "         203       0.00      0.00      0.00         1\n",
      "         212       0.00      0.00      0.00         1\n",
      "         214       0.00      0.00      0.00         1\n",
      "         215       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.20       100\n",
      "   macro avg       0.04      0.06      0.04       100\n",
      "weighted avg       0.11      0.20      0.12       100\n",
      "\n",
      "------------------------------\n",
      "Classification report for output column 5:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.30      1.00      0.46        24\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       0.00      0.00      0.00         5\n",
      "           6       0.00      0.00      0.00         3\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00         2\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         1\n",
      "          24       0.00      0.00      0.00         1\n",
      "          25       0.00      0.00      0.00         1\n",
      "          30       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         3\n",
      "          42       0.00      0.00      0.00         2\n",
      "          43       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         1\n",
      "          56       0.00      0.00      0.00         1\n",
      "          61       0.00      0.00      0.00         1\n",
      "          62       0.00      0.00      0.00         1\n",
      "          73       0.00      0.00      0.00         1\n",
      "          81       0.00      0.00      0.00         2\n",
      "          83       0.00      0.00      0.00         2\n",
      "          84       0.00      0.00      0.00         1\n",
      "          87       0.00      0.00      0.00         1\n",
      "          90       0.00      0.00      0.00         1\n",
      "         102       0.00      0.00      0.00         1\n",
      "         116       0.00      0.00      0.00         1\n",
      "         138       0.00      0.00      0.00         1\n",
      "         141       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         1\n",
      "         147       0.00      0.00      0.00         1\n",
      "         159       0.00      0.00      0.00         1\n",
      "         169       0.00      0.00      0.00         1\n",
      "         172       0.00      0.00      0.00         1\n",
      "         175       0.00      0.00      0.00         1\n",
      "         186       0.00      0.00      0.00         1\n",
      "         223       0.00      0.00      0.00         1\n",
      "         229       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.44       100\n",
      "   macro avg       0.05      0.07      0.05       100\n",
      "weighted avg       0.27      0.44      0.31       100\n",
      "\n",
      "------------------------------\n",
      "Classification report for output column 6:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       0.32      1.00      0.49        18\n",
      "           4       1.00      1.00      1.00        24\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         3\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         2\n",
      "          24       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          70       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         1\n",
      "         101       0.00      0.00      0.00         1\n",
      "         121       0.00      0.00      0.00         1\n",
      "         124       0.00      0.00      0.00         1\n",
      "         125       0.00      0.00      0.00         1\n",
      "         137       0.00      0.00      0.00         1\n",
      "         140       0.00      0.00      0.00         1\n",
      "         158       0.00      0.00      0.00         1\n",
      "         162       0.00      0.00      0.00         1\n",
      "         171       0.00      0.00      0.00         1\n",
      "         172       0.00      0.00      0.00         1\n",
      "         180       0.00      0.00      0.00         1\n",
      "         181       0.00      0.00      0.00         2\n",
      "         186       0.00      0.00      0.00         1\n",
      "         204       0.00      0.00      0.00         1\n",
      "         224       0.00      0.00      0.00         1\n",
      "         254       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62       100\n",
      "   macro avg       0.07      0.09      0.07       100\n",
      "weighted avg       0.50      0.62      0.53       100\n",
      "\n",
      "------------------------------\n",
      "Classification report for output column 7:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        44\n",
      "           1       0.34      1.00      0.51        13\n",
      "           4       1.00      1.00      1.00        18\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "          11       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "          19       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         1\n",
      "          26       0.00      0.00      0.00         1\n",
      "          29       0.00      0.00      0.00         2\n",
      "          32       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         1\n",
      "          54       0.00      0.00      0.00         1\n",
      "          62       0.00      0.00      0.00         1\n",
      "          68       0.00      0.00      0.00         1\n",
      "          76       0.00      0.00      0.00         1\n",
      "          87       0.00      0.00      0.00         1\n",
      "          92       0.00      0.00      0.00         1\n",
      "         111       0.00      0.00      0.00         1\n",
      "         161       0.00      0.00      0.00         1\n",
      "         178       0.00      0.00      0.00         2\n",
      "         205       0.00      0.00      0.00         1\n",
      "         209       0.00      0.00      0.00         1\n",
      "         210       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.75       100\n",
      "   macro avg       0.09      0.12      0.10       100\n",
      "weighted avg       0.66      0.75      0.69       100\n",
      "\n",
      "------------------------------\n",
      "Classification report for output column 8:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        62\n",
      "           1       0.40      1.00      0.57        10\n",
      "           4       1.00      1.00      1.00        13\n",
      "           9       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         1\n",
      "          29       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          99       0.00      0.00      0.00         2\n",
      "         114       0.00      0.00      0.00         1\n",
      "         136       0.00      0.00      0.00         1\n",
      "         203       0.00      0.00      0.00         1\n",
      "         237       0.00      0.00      0.00         1\n",
      "         243       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.85       100\n",
      "   macro avg       0.14      0.18      0.15       100\n",
      "weighted avg       0.79      0.85      0.81       100\n",
      "\n",
      "------------------------------\n",
      "Classification report for output column 9:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        75\n",
      "           1       0.73      1.00      0.85        11\n",
      "           4       1.00      1.00      1.00        10\n",
      "           6       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         1\n",
      "          45       0.00      0.00      0.00         1\n",
      "         201       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.96       100\n",
      "   macro avg       0.39      0.43      0.41       100\n",
      "weighted avg       0.93      0.96      0.94       100\n",
      "\n",
      "------------------------------\n",
      "Classification report for output column 10:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        85\n",
      "           1       0.50      1.00      0.67         2\n",
      "           4       1.00      1.00      1.00        11\n",
      "          67       0.00      0.00      0.00         1\n",
      "         183       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.98       100\n",
      "   macro avg       0.50      0.60      0.53       100\n",
      "weighted avg       0.97      0.98      0.97       100\n",
      "\n",
      "------------------------------\n",
      "Classification report for output column 11:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        96\n",
      "           1       1.00      1.00      1.00         2\n",
      "           4       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00       100\n",
      "   macro avg       1.00      1.00      1.00       100\n",
      "weighted avg       1.00      1.00      1.00       100\n",
      "\n",
      "------------------------------\n",
      "Classification report for output column 12:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        98\n",
      "           4       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00       100\n",
      "   macro avg       1.00      1.00      1.00       100\n",
      "weighted avg       1.00      1.00      1.00       100\n",
      "\n",
      "------------------------------\n",
      "Classification report for output column 13:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           1.00       100\n",
      "   macro avg       1.00      1.00      1.00       100\n",
      "weighted avg       1.00      1.00      1.00       100\n",
      "\n",
      "------------------------------\n",
      "Classification report for output column 14:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           1.00       100\n",
      "   macro avg       1.00      1.00      1.00       100\n",
      "weighted avg       1.00      1.00      1.00       100\n",
      "\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Predict using the model\n",
    "y_pred = model.predict([x_val, y_val[:,:-1]])\n",
    "y_pred = np.argmax(y_pred, axis=-1)  # Get the class with the highest probability\n",
    "\n",
    "# Flatten the true labels to match the shape of predictions\n",
    "y_true = y_val[:, 1:]\n",
    "\n",
    "# Iterate over output columns and print classification report for each\n",
    "for i in range(y_true.shape[1]):\n",
    "    print(f\"Classification report for output column {i + 1}:\")\n",
    "    print(classification_report(y_true[:, i], y_pred[:, i]))\n",
    "    print(\"-\" * 30) # Add a separator between reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V93HPoh7LwO3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
